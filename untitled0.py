# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16KyDCqzjnfpW6iXrhTQEPsSO43Rw1I8b
"""

# https://www.kaggle.com/bletchley/course-material-walmart-challenge?select=train.csv
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error

import pandas as pd 
from google.colab import drive
drive.mount('/content/gdrive')

df = pd.read_csv('/content/gdrive/MyDrive/Методы анализа данных/Головко/data/train.csv')
df

df.isna().sum()

df.drop(['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5', 'Date'], axis=1 ,inplace=True)

df

df['IsHoliday'] = df['IsHoliday'].astype(int)
le = LabelEncoder()
le.fit(df['Type'])
df['Type'] = le.transform(df['Type'])
df

for i in df:
  sns.histplot(df[i], bins=40 )
  plt.show()

plt.figure(figsize = [14,16])
sns.heatmap(df.corr() , annot = True)

X_train, X_test, y_train, y_test = train_test_split(df, df['Size'], test_size=0.33)

tree = DecisionTreeRegressor()
tree.fit(X_train, y_train)
pred = tree.predict(X_test)
mean_absolute_error(y_test, pred)

